{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6dcd6d3",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae9ec9",
   "metadata": {},
   "source": [
    "First thing first, let me import the Python libraries first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f67192",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f214d49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:24:16.286655600Z",
     "start_time": "2023-12-21T22:24:16.110420100Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')  # add ../src to sys.path\n",
    "from FiDaL import (data as dta, plot, utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d0af7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:24:16.350328400Z",
     "start_time": "2023-12-21T22:24:16.116944300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the credentials from credentials.json\n",
    "with open('../config/credentials.json') as f:\n",
    "    credentials = json.load(f)\n",
    "    \n",
    "    # Read the config from config.json\n",
    "with open('../config/config.json') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2f9334",
   "metadata": {},
   "source": [
    "## Download and load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692404b930bcbb31",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Selecting the right data period is crucial for the analysis. The following factors should be considered when selecting the data period:\n",
    "- **Market changes**: Financial markets undergo structural changes over time. Regulations, economic conditions, technological advancements, and other factors can alter market dynamics. It's crucial to ensure that the data used is still representative of current conditions.\n",
    "- **More Recent Data**: Some analysts prefer using more recent data (e.g., 3-5 years) on the premise that it better reflects the current market dynamics. Financial markets evolve, and the factors that influenced stock performance a decade ago may not be as relevant today.\n",
    "- **Specific Asset Characteristics**: Different assets may require different look-back periods based on their volatility, liquidity, and the sectors they represent. For instance, technology stocks may behave differently compared to utility stocks over the same period.\n",
    "- **Investment Horizon**: Align the data period with your investment horizon. If you are a long-term investor, using a longer historical period may be more appropriate. For shorter-term investments, consider using a shorter data period.\n",
    "- **Statistical Significance:** Ensure that the data set is large enough to be statistically significant, reducing the risk of anomalies skewing the results.\n",
    "- Be aware of **regime changes** (significant shifts in market trends or economic conditions) within your data period. These can significantly impact the relevance of historical data.\n",
    "- **Consider using rolling windows** for your analysis. This technique involves continuously updating the time frame of the data used for the analysis (e.g., always using the most recent five years of data). This can provide a more dynamic view of how optimal weights change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228abe11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:24:17.056332500Z",
     "start_time": "2023-12-21T22:24:16.129467100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an instance of the YFDataDownloader class\n",
    "downloader = dta.make_data.YFDataDownloader(config, credentials=credentials)\n",
    "\n",
    "# Get the data for the tickers to analyze using downloader.get_data()\n",
    "print(config[\"data_source_params\"])\n",
    "data_downloaded = downloader.get_data(**config[\"data_source_params\"])\n",
    "data = data_downloaded[[\"Adj Close\", \"Volume\"]]\n",
    "del data_downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b11380240fed28c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ada6ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:24:17.059374700Z",
     "start_time": "2023-12-21T22:24:16.466065900Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5a7ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:24:17.060389Z",
     "start_time": "2023-12-21T22:24:16.478350Z"
    }
   },
   "outputs": [],
   "source": [
    "data = (data.dropna(thresh=data.shape[1]//2)\n",
    "        .rename(columns={\"Adj Close\": \"price\", \"Volume\": \"volume\"})\n",
    "        .sort_index(axis=1))\n",
    "\n",
    "data = dta.process.FinancialDataProcessor.compute_returns(data, column='price', log=True, apply_smoothing=True, smoothing_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa42e4c63e3fabb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:24:17.084205Z",
     "start_time": "2023-12-21T22:24:16.492122500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_returns = data[\"log_returns\"]\n",
    "\n",
    "expected_returns = daily_returns.mean()  # Calculate expected returns (mean of logarithmic returns)\n",
    "\n",
    "print(\"\\nExpected Returns:\\n\", expected_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c06b1a712b9582",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The most important data cleaning steps for us are:\n",
    "- **Missing Values**: Check for missing values and handle them appropriately. Missing values can cause issues with the analysis and may lead to incorrect conclusions. Common approaches for handling missing values include removing them, imputing them with a value (e.g., mean, median), or using a forward or backward fill.\n",
    "- **Outliers**: Check for outliers and handle them appropriately. Outliers can skew the analysis and lead to incorrect conclusions. Common approaches for handling outliers include removing them or capping them at a certain value.\n",
    "- **Data Types**: Ensure that the data types are correct. For instance, numerical values should be represented as floats or integers, and dates should be represented as date objects.\n",
    "- **Duplicates**: Check for duplicate values and handle them appropriately. Duplicates can cause issues with the analysis and may lead to incorrect conclusions. Common approaches for handling duplicates include removing them or aggregating them.\n",
    "- **Data Integrity**: Ensure that the data is correct and consistent. For instance, check that the data is in the expected range, and that the values are consistent with other data sources.\n",
    "- **Data Format**: Ensure that the data is in the expected format. For instance, check that the data is in the expected units (e.g., dollars vs. cents), and that the values are consistent with other data sources.\n",
    "- **Data Range**: Ensure that the data is within the expected range. For instance, check that the data is within the expected time period, and that the values are consistent with other data sources.\n",
    "- **Data Granularity**: Ensure that the data is at the expected level of granularity. For instance, check that the data is at the expected frequency (e.g., daily, monthly, quarterly), and that the values are consistent with other data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca5e2ecf130afca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's apply all of these with the expection of outliers, and granulatiry because we can have outliners that are valid as we will see so these are things that we will need to check mostly manually, and granularity is already set to daily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbfce91",
   "metadata": {},
   "source": [
    "## Visual analzysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c153d913",
   "metadata": {},
   "source": [
    "### Volume vs price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b7dbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:24:17.351212900Z",
     "start_time": "2023-12-21T22:24:16.499105200Z"
    }
   },
   "outputs": [],
   "source": [
    "plot.adj_close_volume(data, columns=[\"price\", \"volume\"], y_log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5e4eb1bfaf94c5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36570c99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:24:17.962289900Z",
     "start_time": "2023-12-21T22:24:17.097285300Z"
    }
   },
   "outputs": [],
   "source": [
    "plot.moving_average(adj_close:=data[\"price\"],\n",
    "                    volume:=data[\"volume\"],\n",
    "                    window_sizes=[10, 20], include_stats=True, log_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3924c948",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:24:17.963291900Z",
     "start_time": "2023-12-21T22:24:17.560047500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculating volatility (annualized standard deviation of daily returns)\n",
    "volatility = daily_returns.std() * (252**0.5) # Volatility is the annualized standard deviation of daily returns\n",
    "correlation = daily_returns.dropna().corr(other=data[\"volume\"].dropna())  # Calculate correlation between logarithmic returns and volume\n",
    "daily_returns.describe(), volatility, correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6d4fe9",
   "metadata": {},
   "source": [
    "# 1. Component decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534dce04",
   "metadata": {},
   "source": [
    "## 1.1 Seasonal decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c900e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:24:19.130984800Z",
     "start_time": "2023-12-21T22:24:17.577197200Z"
    }
   },
   "outputs": [],
   "source": [
    "decomposed = seasonal_decompose(data[\"price\"].interpolate(),\n",
    "                                    model='additive', period=len(data) // 2)\n",
    "fig = plot.decomposed_time_series(decomposed, ticker:=\"APPL\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20f52eb",
   "metadata": {},
   "source": [
    "## 1.2 Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5964a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:24:19.496951800Z",
     "start_time": "2023-12-21T22:24:19.132986600Z"
    }
   },
   "outputs": [],
   "source": [
    "plot.autocorrelation(data[\"price\"], title=ticker, lags=30, figsize=(7, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff037087",
   "metadata": {},
   "source": [
    "## 1.3 Partial Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb8e0d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:25:24.201069300Z",
     "start_time": "2023-12-21T22:25:24.014064700Z"
    }
   },
   "outputs": [],
   "source": [
    "plot.partial_autocorrelation(data[\"price\"].diff(), title=ticker, lags=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e990f77",
   "metadata": {},
   "source": [
    "## 1.4 Test stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9254c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:24:19.926005300Z",
     "start_time": "2023-12-21T22:24:19.737035800Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n',ticker, 'Dickey-Fuller Test for stationarity:')\n",
    "_ = utils.test_stationarity(timeseries=data[\"price\"]\n",
    "                        .interpolate(),\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d59e6e2",
   "metadata": {},
   "source": [
    "To ensure that your time series data is stationary, a common technique is differencing. Differencing involves computing the differences between consecutive observations. This technique is particularly effective in removing trends and seasonality, which are common reasons for non-stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed09c324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:24:19.927006100Z",
     "start_time": "2023-12-21T22:24:19.794342600Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n',ticker, 'Dickey-Fuller Test for stationarity:')\n",
    "_ = utils.test_stationarity(timeseries=data[\"price\"]\n",
    "                        .interpolate()\n",
    "                        .diff().dropna(),\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3767816e",
   "metadata": {},
   "source": [
    "# 2. Traditional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce6a500",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:24:19.929072200Z",
     "start_time": "2023-12-21T22:24:19.822912900Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Determine Optimal Number of Lags\n",
    "lag_acf = acf(timeseries:=data[\"price\"].diff().dropna(), nlags=40)\n",
    "lag_acf  # Inspect the lag_acf to choose short-term and long-term lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee119b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:25:57.568331900Z",
     "start_time": "2023-12-21T22:25:57.226863Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Plot SMA and EMAs\n",
    "plot.analyze_moving_averages(timeseries,\n",
    "                        short_term_lag=10,\n",
    "                        long_term_lag=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e6276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T22:58:38.926222200Z",
     "start_time": "2023-12-21T22:58:38.851409Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "data_diff = data[\"price\"].diff().dropna()\n",
    "train_size = int(len(data_diff) * 0.95)\n",
    "\n",
    "# Use differenced data for the autoregressive model\n",
    "train, test = data[:train_size], data[train_size:]\n",
    "train_diff, test_diff = data_diff[:train_size], data_diff[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f2cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T23:01:53.604002700Z",
     "start_time": "2023-12-21T23:01:53.494121300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the optimal lags based on PACF analysis\n",
    "optimal_lags = 20\n",
    "\n",
    "# Fit AutoReg model\n",
    "model = AutoReg(train_diff, lags=optimal_lags)\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model_fit.predict(start=len(train_diff), end=len(train_diff) + len(test_diff) - 1)\n",
    "predictions.index = test_diff.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d10ee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T23:01:54.586655500Z",
     "start_time": "2023-12-21T23:01:54.297420700Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(test_diff, label='Actual Stock Price', c='b')\n",
    "plt.plot(predictions, c='r', label='Prediction')\n",
    "plt.title('Predicted Stock Price-AT&T')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c14ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T23:01:54.884119400Z",
     "start_time": "2023-12-21T23:01:54.664366Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(test_diff, predictions))\n",
    "print(f'RMSE for {ticker}: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3248808c810ba98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T00:22:57.216470600Z",
     "start_time": "2023-12-22T00:22:57.138338Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Specify the order of the ARIMA model\n",
    "order = (7,1,7)\n",
    "\n",
    "# Fit the ARIMA model\n",
    "model = ARIMA(data[\"price\"], order=order)\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model_fit.predict(start=len(train_diff), end=len(train_diff) + len(test_diff) - 1)\n",
    "predictions.index = test_diff.index\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(test_diff, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4828de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'RMSE for ARIMA: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff18e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(test['price'], label='Actual Stock Price', c='b')\n",
    "plt.plot(predictions, c='r', label='Prediction')\n",
    "plt.title('Predicted Stock Price-AT&T')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646e21e8",
   "metadata": {},
   "source": [
    "# 3. Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b11f1b",
   "metadata": {},
   "source": [
    "## Data preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae7cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_diff_train, y_diff_train = dta.process.split_sequence(train_diff, n_steps:=10)\n",
    "X_diff_train = X_diff_train.reshape((X_diff_train.shape[0],\n",
    "                                         X_diff_train.shape[1], n_features:=1))\n",
    "\n",
    "X_diff_test, y_diff_test = dta.process.split_sequence(test_diff.values, n_steps)\n",
    "X_diff_test = X_diff_test.reshape((X_diff_test.shape[0],\n",
    "                                       X_diff_test.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd850257",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
